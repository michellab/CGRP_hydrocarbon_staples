{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def process_file(input_file, work_dir, residue_number, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Processes a single *_freq.tsv file, rearranges residues, applies a threshold filter for contact frequency,\n",
    "    and includes the interaction type (extracted from the file name).\n",
    "    Args:\n",
    "        input_file (str): The name of the input file.\n",
    "        work_dir (str): The directory where the files are located.\n",
    "        residue_number (str): The residue number extracted from the input file name.\n",
    "        threshold (float): The contact frequency threshold for inclusion in the output.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    interaction_type = re.search(r'_(\\w+)_interactions_freq\\.tsv', input_file)\n",
    "    if interaction_type:\n",
    "        interaction_type = interaction_type.group(1)\n",
    "        if interaction_type == \"hplp\":\n",
    "            interaction_type = \"hp\"\n",
    "    else:\n",
    "        interaction_type = \"unknown\"\n",
    "\n",
    "    with open(work_dir + input_file, 'r') as infile:\n",
    "        for line in infile:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            \n",
    "            parts = line.strip().split('\\t')\n",
    "\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "\n",
    "            residue_1 = parts[0]\n",
    "            residue_2 = parts[1]\n",
    "            contact_frequency = float(parts[2])\n",
    "            \n",
    "            if 'all' in residue_1 or 'all' in residue_2 or 'all' in interaction_type:\n",
    "                continue\n",
    "            if 'pc' in residue_1 or 'pc' in residue_2 or 'pc' in interaction_type:\n",
    "                continue\n",
    "            \n",
    "            if contact_frequency < threshold:\n",
    "                continue\n",
    "\n",
    "            residue_1 = residue_1[2:]\n",
    "            residue_2 = residue_2[2:]\n",
    "\n",
    "            residue_1_number = int(residue_1.split(':')[1]) \n",
    "            residue_2_number = int(residue_2.split(':')[1]) \n",
    "            if residue_1_number > arg18_pos or residue_2_number > arg18_pos:                                                    #change this if needed, 468 is Arg18 in CGRP helix\n",
    "                continue\n",
    "\n",
    "            target_residue_1 = f\"{residue_1.split(':')[0]}:{residue_number}\"\n",
    "            target_residue_2 = f\"{residue_2.split(':')[0]}:{residue_number}\"\n",
    "\n",
    "            if residue_1 == target_residue_1:\n",
    "                processed_data.append(f\"{residue_1} {residue_2} {interaction_type} {contact_frequency}\")\n",
    "            elif residue_2 == target_residue_2:\n",
    "                processed_data.append(f\"{residue_2} {residue_1} {interaction_type} {contact_frequency}\")\n",
    "            else:\n",
    "                processed_data.append(f\"{residue_1} {residue_2} {interaction_type} {contact_frequency}\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "def process_all_files(work_dir, output_file, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Processes all *_freq.tsv files in the given directory and combines their contents into one output file.\n",
    "    Args:\n",
    "        work_dir (str): The directory where the files are located.\n",
    "        output_file (str): The name of the combined output file to save the processed data.\n",
    "        threshold (float): The contact frequency threshold for inclusion in the output.\n",
    "    \"\"\"\n",
    "    all_processed_data = []\n",
    "\n",
    "    for filename in os.listdir(work_dir):\n",
    "        if filename.endswith('freq.tsv'):\n",
    "            residue_number_match = re.search(r'(\\d+)_.*\\.tsv', filename)\n",
    "            if residue_number_match:\n",
    "                residue_number = residue_number_match.group(1)\n",
    "                residue_number = int(residue_number)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if residue_number >= ace_pos and residue_number <= arg18_pos:                         #change this if needed\n",
    "                processed_data = process_file(filename, work_dir, str(residue_number), threshold)\n",
    "                all_processed_data.extend(processed_data)\n",
    "\n",
    "    def sort_key(line):\n",
    "        \"\"\"\n",
    "        Helper function to extract the residue number from a line and sort it in ascending order.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            residue = line.split()[0]\n",
    "            residue_number = re.search(r'(\\d+):', residue).group(1)\n",
    "            return int(residue_number)\n",
    "        except AttributeError:\n",
    "            return float('inf')\n",
    "\n",
    "    all_processed_data.sort(key=sort_key)\n",
    "\n",
    "    with open(work_dir + output_file, 'w') as outfile:\n",
    "        for line in all_processed_data:\n",
    "            outfile.write(line + '\\n')\n",
    "\n",
    "    print(f\"File processing complete. All data (above threshold) saved to: {work_dir + output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter directory and file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/mnt/storage1/adam/CGRP/New/CGRP1-37/ligand_receptor_interactions/'\n",
    "ace_pos = 469                                                                   #or val8_pos\n",
    "arg18_pos = 479\n",
    "output_file = 'combined_processed_freq_sorted_with_interaction_type.tsv'\n",
    "input_file = 'combined_processed_freq_sorted_with_interaction_type.tsv'\n",
    "\n",
    "process_all_files(work_dir, output_file, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ligand-ligand contact interaction map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def map_residue(residue):\n",
    "    \"\"\"\n",
    "    Map a residue like ACE:357 to ACE7, VAL:458 to VAL8, and so on.\n",
    "    Stops mapping at ARG:468 and excludes residues beyond this range.\n",
    "    \n",
    "    Args:\n",
    "        residue (str): The residue in the form \"RES:NUMBER\".\n",
    "    Returns:\n",
    "        str: The mapped residue in the form \"RES#\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        res_name, res_number = residue.split(\":\")\n",
    "        res_number = int(res_number) \n",
    "    except ValueError:\n",
    "        print(f\"Error processing residue: {residue}\")\n",
    "        return None\n",
    "\n",
    "   \n",
    "    if res_number >= ace_pos and res_number <= arg18_pos:                                             \n",
    "        mapped_residue = f\"{res_name}{res_number - 455}\"       #change this if needed\n",
    "        return mapped_residue\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_tsv_and_create_table(input_file, work_dir):\n",
    "    \"\"\"\n",
    "    Processes the input TSV file and creates a table with residues sorted in ascending order by their residue number.\n",
    "    Displays only the interactions of residue_1, showing each interaction type on a separate line.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): The name of the TSV file to process.\n",
    "        work_dir (str): The directory where the file is located.\n",
    "    \"\"\"\n",
    "    file_path = work_dir + input_file\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=' ', header=None, names=[\"residue_1\", \"residue_2\", \"interaction_type\", \"contact_frequency\"])\n",
    "        \n",
    "        print(\"Loaded data:\")\n",
    "        print(df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    df['mapped_residue_1'] = df['residue_1'].apply(map_residue)\n",
    "    df['mapped_residue_2'] = df['residue_2'].apply(map_residue)\n",
    "\n",
    "    # Replace \"HID\" or \"HIE\" with \"HIS\" in mapped residues\n",
    "    df['mapped_residue_1'] = df['mapped_residue_1'].str.replace(\"HID\", \"HIS\").str.replace(\"HIE\", \"HIS\")\n",
    "    df['mapped_residue_2'] = df['mapped_residue_2'].str.replace(\"HID\", \"HIS\").str.replace(\"HIE\", \"HIS\")\n",
    "\n",
    "    df = df.dropna(subset=['mapped_residue_1', 'mapped_residue_2'])\n",
    "    df = df.dropna(subset=['mapped_residue_1', 'mapped_residue_2'])\n",
    "\n",
    "    def get_residue_number(residue):\n",
    "        \"\"\"\n",
    "        Extracts the last one or two numeric digits at the end of the residue for sorting.\n",
    "        E.g., \"R5112\" will be treated as 12.\n",
    "        \"\"\"\n",
    "        match = re.search(r'(\\d{1,2})$', residue)\n",
    "        if match:\n",
    "            return int(match.group())\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    all_residues = sorted(set(df['mapped_residue_1'].unique()), key=get_residue_number)\n",
    "\n",
    "    interaction_dict = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        residue_1 = row['mapped_residue_1']\n",
    "        residue_2 = row['mapped_residue_2']\n",
    "        interaction_type = row['interaction_type']\n",
    "        contact_frequency = round(row['contact_frequency'] * 100)  # Convert to percentage\n",
    "\n",
    "        interaction_dict[residue_1][residue_2].append(f\"{interaction_type} {contact_frequency}%\")\n",
    "\n",
    "    interaction_matrix = pd.DataFrame('', index=all_residues, columns=all_residues)\n",
    "    interaction_matrix = pd.DataFrame('', index=all_residues, columns=all_residues)\n",
    "\n",
    "    for residue_1 in all_residues:\n",
    "        for residue_2 in all_residues:\n",
    "            if residue_1 == residue_2:\n",
    "                continue \n",
    "            \n",
    "            if residue_2 in interaction_dict[residue_1]:\n",
    "                interactions = '\\n'.join(interaction_dict[residue_1][residue_2])\n",
    "                interaction_matrix.at[residue_1, residue_2] = interactions\n",
    "            else:\n",
    "                interaction_matrix.at[residue_1, residue_2] = \"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.axis('off')\n",
    "\n",
    "    cell_colours = [['white' for _ in range(len(all_residues))] for _ in range(len(all_residues))]  # Default to white\n",
    "\n",
    "    for i in range(len(all_residues)):\n",
    "        cell_colours[i][i] = 'lightgrey'\n",
    "\n",
    "        if i + 4 < len(all_residues):\n",
    "            cell_colours[i][i + 4] = 'lightcoral'\n",
    "            cell_colours[i + 4][i] = 'lightcoral'\n",
    "\n",
    "    table = ax.table(cellText=interaction_matrix.values, \n",
    "                colLabels=interaction_matrix.columns, \n",
    "                rowLabels=interaction_matrix.index,\n",
    "                loc='center', \n",
    "                cellLoc='center', \n",
    "                cellColours=cell_colours)\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 8)\n",
    "\n",
    "    output_image_path = work_dir + 'all_interaction_table_lig_lig_helix'\n",
    "    plt.savefig(output_image_path, bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "\n",
    "    print(f\"Table image saved to {output_image_path}\")\n",
    "\n",
    "process_tsv_and_create_table(input_file, work_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
